머신러닝실습 발표 주제 !

 

머신러닝이 무엇이다! 라는 것도 공부하고 모델도 배우고 알고리즘도 배웠어요 알겠어요 데이터를 넣고 모델링을 하면 예쁜 모델이 나오고 그 모델을 기반으로 새로운 입력을 넣었을 때 아웃풋이 짠 하고 나오는거죠? 근데 그 모델이 왜 그렇게 생겼을까 대한 의문이 생겼습니다. 

 

주제 선정 이유 : 머신러닝 관련 논문들을 볼 때 모델링 / 알고리즘에 대한 의문이 들었다.

 

추상적으로 activation function이나 layer 혹은 기타 장치의 추가로 인해 성능이 좋아졌구나는 알 수 있지만 레이어의 depth 나 개수 등 은 이유는 모르고 많이 해봤는데 이게 제일 좋았다 라고 이해를 할 수 밖에 없었음.

그래서 blackbox 를 파해쳐보자! 왜 그런지 궁금했어요 저는! 주에 CNN, 두번쨰로 DCGAN 등 NN등 개인적으로는 이미지 처리에 관심이 있고 보이는게 일단 있으니까 이런 것들로 할까도 생각했는데 오늘 제가 주제로 잡은건 black box 파해치기 입니다! 

 

REF : 

https://www.youtube.com/watch?v=xlmlY8WHjkU&index=30&list=PL0oFI08O71gKEXITQ7OG2SCCXkrtid7Fq

\#28. Understanding Black-box Predictions via Influence Functions (ICML2017 베스트페이퍼)

 

Tensorflow KR에서 진행하고 있는 논문읽기 모임 PR12에서 발표한 저의 네번째 발표입니다. 이번에는 ICML2017에서 베스트페이퍼상을 받은 "딥러닝의 결과를 어떻게 이해할 수 있는가"에 대한 논문을 리뷰해보았습니다.

 

딥러닝은 성능은 좋지만 왜 그게 잘되는지 모르는, 그야말로 "블랙박스"와 같은 모델인데요, 이 논문에서는 '만약 A라는 트레이닝 데이터가 없다면 어떤 변화가 일어날까?', 'B라는 테스트 이미지에 가장 결정적인 영향을 주는 트레이닝 데이터는 무엇일까?'와 같은 질문에 대해 influence function이라는 것을 도입해서 해결하려 하였습니다.

 

"Understanding Black-box Predictions via Influence Functions", Pang Wei Koh and Percy Liang, 2017

[Link] http://proceedings.mlr.press/v70/koh17a.html

 

[YouTube] https://www.youtube.com/watch…

[Slides] https://www.slideshare.net/…/understanding-blackbox-predict…


 

 

[Youtube 강의 노트]

**PR-035 :  Understanding Black-box Predictions via Influence Functions**

\-      ICML 2017 에서 Best Paper

\-      Youtube에 저자가 발표한 영상이 올라가 있음

\-      Microsoft research 에서 세미나 진행 – 영상 보자!

\-      2017년 4월 

 

l  Questions

이 논문은 questions 에 대해 답을 하는 형식

n  How can we explain the predictions of a black-box model

어떻게 블랙박스 모델의 예측을 설명할 수 있는가?

n  Why did the system make this prediction

왜 이 시스템이 이러한 예측을 만들어 냈는가?

n  How can we explain where the model came from?

그렇다면 이 모델은 도대체 어디서 온 것이냐?

n  What would happen if the values of a training point where slightly changed?

만약 트레이닝 값이 조금이라도 변화한다면 어떤 일이 일어날 것인가?

ð  In this paper, we tackle this question by tracing a model’s predictions through its learning algorithm and back to the training data, where the model parameters ultimately derive from.

그동안 많은 노력이있었지만 기존은 모델의 사인튜닝까지 갖고 옵티멀 파라미터가 가지면 그걸 해석하는 노력을 했다. 여기선 traing example에 따라 loss, parameter가 어떻게 변하는지에 대하 ㄴ관점, 즉 model을 traing data에 대한 함수다 라는 관점에서 interpretation을 한 것이다. 

 

l  Interpretation of dl results

\-      Black box model 혹은 visualization과 관련한 기존 논문들

\-      결과를 해석하는 방법

n  가장 activate를 잘 시키는 input을 살펴보기

n  어느부위가 가자 ㅇactivate되는가에 대해

n  각각 부분에 대해 simpler model을 만들어서 해석하고자 하는 것

n  다른점 :  모델을 구해서 고정하고 그 다음해석

n  이아니라 

 

l  Influence of Training point

n  What is the influence of a training example for the model (or for the loss of a test example)?

n  Influence on the parameter : z 에 대한 영향력을 웨이팅 했을 때 파라미터는 어떻게 변화할 것인가!?

70년대부터 있던 방법이라고 합니다. 

 

n  Influence vs Euclidean distance

I function이 어떻게 영향이 있냐를 알아보기 위한 그래프. SVM같은 경우는 가로축이 Euclidean distance 왼쪽으로 갈수록 픽셀단위의 유클리안디스턴스에 가깝다는 것 , 픽섹벨류가 가까운 것들이 +든 – 든 영향을 많이 줬다는 것. 서포트 벡터, 바운더리에가까운 것드링 가장 중요한 역할을 한다 비슷한데도 불구하고- 혹으 ㄴ=의 결과를 낳는것들. 반면 NN가은 경우에는 Neural net INceptionㅇ 같은 경우에는 영향력을ㅇ 많이 주는 example 은 ㄱ물고기 두마리가 나와싸다. 이게 바로 representation learning SVM 보다 훨씬 고차원적인 모델이구나

n  Ex의 영향력을 보려면 100개중에 1번 뺴고 트레이닝 쭉 해보는건데 이렇게 하는게 아니라 리트레이닝 대신에 비슷한거 사용하는 것이다. 

n  Parameter 말고 loss 에는 무슨 영향을 끼치게 되는가? Chain rule을 가지고 수식을 풀어나간다. Model parameter의 영향과 test에 대한 loss의 영향을 합친 것이 어떠한 트레이닝 example 을 변화시켰을 때 특정한 Test loss를 증가시킬 영향함수다. 

n  수식의 차이점 어디에 대한 것인가??

n   

 

l  Example

n  그래프 보는 방법은 7과 1을 구분하는 task 초록색은 train test 7 7  빨간색 1 7 

n  1같이 생간 7이 test 이미지라면 7에 선그어진 사진은 harmful 한 training 

 

l  Several problems 

n  헤시안 인버스 계산이 한시간은 걸리겠죠…?

최적화 연구에서 많이되고 있댱

n   

​    c9