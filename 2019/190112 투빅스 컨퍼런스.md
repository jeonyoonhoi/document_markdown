# 투빅스 컨퍼런스

* 일시 : 2019-01-12 14:00~18:00
* 장소 :  네이버 D2 (강남 메리츠타워 16층 )



## [선박구조]



### 03. 환경구성 강화학습 알고리즘 

가정 드론이 바다 위에서 바다를 보고 있고, 에이전트가 현재 상황에서 물체를 모두 인식할 수 있다고 가정



- 리워드(가중치)를 통해 사람에 우선순위를 둠

사람 +10 기름 +1



2. 강화학습 알고리즘 

   ##### DQN 

   - Q-Learning을 이용

   ##### REINFORCE

   ##### A2C

   timestamp 마다 학습된다는 차이점이 있음!!

   > 세 가지 모델 모두를 학습하여 비교함. 





### 04. 진행과정 & 학습결과

1. convolutional 전체적인  (사람 + 기름)
2. 사람과 기름 각각 따로 해결
3. 암초를 추가하여 환경을 변경



#### 1) 같이

Q. 하이퍼파라미터를 다르게 두지 않고 하나로 전체에서 통일시켰다 모델마다 최적의 값이 다른 게 아닌가.



- linear 에서 softmax 로 바뀌면서 

actor critic policy  

critic은 state에 대한 설명을 내준다. 



- 결과가 잘 나오지 않음
- 구석에 쳐박히거나 리워드가 0이거나



#### 2) conv1D의ㅣ 커널사이즈 변화시킴 (각각 넣음)

- Reinforce 모델의 경우 잘 나오지 않음 

- 성능의 경우에는 DQN 이 A2C 보다 높음 



#### 3) 암초를 추가해서 에피소드의 난이도 높임 



## 딥러닝을 이용한 수능문제풀이

#### model 1. LSTM 

데이터의 sentence를 사용해 자기자신을 

seq2seq

프리트레이닝 적용시키기



#### model 2. Deep LSTM model



#### model 3. BERT

BERT NLP 에서 핫한모델 ~.~

- INput

  - segment 임베딩, token 임베딩 
  -  

- PRetrain 

  - 문장두개가 들어가면 반절은 다음뭊ㄴ장으로 만들고 나머지는 랜덤하게 ㅊㅜ출해서 만든다. 
  - 다음문장인지 랜덤인지 
  - 마스킹 작업 - 마스크 라는 토큰으로 지우는 과정, 전체 토큰의 15%를 마스크 작업을 해준다. 
  - 80퍼센트는 마스킹 10퍼센트 랜덤 10퍼센트 원레 텍스트
  - LOss 에서 minmax

- Encoder

  - self attention 
  - 어떤 단어가 들어왔을때 앞에 임베딩에서 워드벡터를 만들고 
  - 뭐리 키 밸류를 만든다. 목적은 쿼리벡터에 가장 맞는 최적의 키와 밸류를 학습시키는 것 
  - 쿼리라는 것이 나왔을 때 키값은 다른 위체에 있는 단어들을 얼마나 포커스를할지 나타내주는 말 


문법 문제같은 경우는 가능하지만

맥락을 통해 풀어야 하는

